{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PrBbhwqH00kz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6YlqM7Z06tC",
    "outputId": "119847e6-bb7d-4509-9fc8-5971a19d7432"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/admin/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i55HLfp91e7S"
   },
   "outputs": [],
   "source": [
    "corpus = movie_reviews.raw()\n",
    "corpus = corpus.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "HIJpiZAz2OwU"
   },
   "outputs": [],
   "source": [
    "unigram_vectorizer = CountVectorizer(analyzer='word', stop_words=\"english\", ngram_range=(1, 1))\n",
    "bigram_vectorizer = CountVectorizer(analyzer='word', stop_words=\"english\", ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GdWL-tjY51hy"
   },
   "outputs": [],
   "source": [
    "unigrams = unigram_vectorizer.fit_transform(corpus)\n",
    "bigrams = bigram_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "rFsbeX2Y54d_",
    "outputId": "f93fa6f8-914e-4681-f920-3754656e092b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['balk', 'balki', 'ball', 'ballad', 'ballads', 'ballard', 'ballentine', 'ballerina', 'ballet', 'balletic', 'ballhaus', 'ballinagra', 'balliol', 'ballisitic', 'ballistic', 'ballistics', 'balloon', 'ballooning', 'balloons', 'ballot', 'ballroom', 'balls', 'ballstein', 'ballyhoo', 'ballyhooed', 'balm', 'balmy', 'balrogs', 'balsan', 'balthazar', 'baltimore', 'balto', 'baltus', 'baluyev', 'bambi', 'bamboo', 'bamboozled', 'banal', 'banalities', 'banality', 'banana', 'bananas', 'bancroft', 'band', 'bandaged', 'bandages', 'bandanna', 'bandaras', 'banderas', 'banderes', 'bandied', 'bandies', 'bandit', 'banditos', 'bandits', 'bandmate', 'bands', 'bandstand', 'bandwagon', 'bane', 'bang', 'banged', 'bangers', 'bangkok', 'bangs', 'bangy', 'banish', 'banished', 'banishes', 'banishment', 'banisters', 'banji', 'banjo', 'banjos', 'bank', 'bankability', 'bankable', 'banker', 'bankers', 'banking', 'bankole', 'bankroll', 'bankrupt', 'bankruptcy', 'banks', 'banned', 'bannen', 'banner', 'banners', 'bannister', 'bannon', 'banquet', 'banquets', 'banshee', 'banter', 'bantering', 'bantu', 'banyon', 'banzai', 'baotian', 'baptism', 'baptist', 'baptiste', 'baptizes', 'bar', 'barage', 'baranski', 'barb', 'barbara', 'barbarians', 'barbaric', 'barbarino', 'barbarity', 'barbatus', 'barbecue', 'barbed', 'barbell', 'barbeque', 'barber', 'barbet', 'barbie', 'barbieri', 'barbs', 'barby', 'barcalow', 'barcelona', 'barclay', 'barcode', 'bard', 'bardem', 'bardsley', 'bare', 'bared', 'bareikis', 'barely', 'barenboim', 'barest', 'barf', 'barfing', 'bargain', 'bargained', 'bargaining', 'bargains', 'barge', 'barges', 'baring', 'bark', 'barked', 'barkeep', 'barkeeps', 'barker', 'barkin', 'barking', 'barks', 'barksdale', 'barletta', 'barlow', 'barmaid', 'barn', 'barnacles', 'barnes', 'barnett', 'barney', 'barnfield', 'barns', 'barntill', 'barnyard', 'baron', 'barondes', 'baronial', 'baroque', 'barr', 'barracades', 'barracking', 'barracks', 'barrage', 'barred', 'barrel', 'barreled', 'barrels', 'barren', 'barreness', 'barrie', 'barrier', 'barriers', 'barring', 'barrister', 'barroom', 'barry', 'barrymore', 'bars', 'barstool', 'bart', 'barta', 'bartellemeo', 'bartender', 'bartenders', 'barter', 'barth', 'bartholomew']\n"
     ]
    }
   ],
   "source": [
    "print(unigram_vectorizer.get_feature_names()[3000:3200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "id": "8t0kh6Ki6E4x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_disturbing_behavior_ frightening', '_do_ look', '_doctor_dolittle_ continues', '_does_ fully', '_does_ nearly', '_does_ sing', '_dog fancy_', '_don it_', '_don t_', '_double_team_ juicing', '_double_team_ let', '_double_team_ managed', '_double_team_ strange', '_dragon bruce', '_dragon_ jason', '_dragonheart_ gee', '_election good', '_election high', '_election_ contain', '_election_ disappointing', '_election_ matthew', '_election_ plot', '_election_ potential', '_election_ president', '_election_ rely', '_entertainment_weekly_ theresa', '_escape new', '_eve bayou_', '_everybody_ makes', '_exactly_ fuller', '_fear_and_loathing_in_las_vegas_ disastrously', '_ferris bueller_', '_fifty_ whispers', '_film freak', '_flirting disaster_', '_four_ credited', '_full_house_ _america', '_gag spoon_', '_gattaca_ _the', '_gattaca_ overshadowed', '_genius_ wants', '_ghost shell_', '_great_ supporting', '_h20_ _scream_2_', '_halloween _h20_', '_halloween_ _the', '_happen_ carefully', '_hard_ware crap', '_have_ seen', '_here_ exclaims', '_highly_ recommended', '_his_ film', '_holy_man_ slow', '_home alone_', '_home_alone_ finally', '_hope floats_', '_huge_ asshole', '_hustler_ magazine', '_i_know _fisherman', '_i_know_what_you_did_last_summer_ _halloween', '_in brief', '_in company', '_in san', '_into_ action', '_is_ clever', '_is_ crime', '_is_ fault', '_is_ good', '_is_ impressive', '_is_ mish', '_is_ movie', '_is_ wonder', '_it wonderful', '_itcom_ cost', '_jerry_maguire_ fact', '_jerry_maguire_ strike', '_john carpenter', '_juliet_ wild', '_jumanji_ brilliant', '_kingpin_ left', '_knock_off_ delivers', '_knock_off_ laughs', '_knock_off_ leave', '_knock_off_ respect', '_knock_off_ time', '_la promesse_', '_last year', '_last_ bruckheimer', '_last_ summer', '_least_ twice', '_leave beaver_', '_life beautiful_', '_little women_', '_loathe_ filmmakers', '_lone star_', '_long_ story', '_looks_ good', '_lot_ butt', '_many_ dot', '_matewan_ instead', '_melvin howard_', '_mind eye_', '_moby dick_', '_more_ slapstick', '_more_ songs', '_more_ talking', '_mortal kombat_', '_murder_ mystery', '_must_ authentic', '_must_ good', '_never kissed_', '_no one_', '_not_ care', '_not_ craft', '_not_ faked', '_not_ leave', '_not_ live', '_october sky_', '_onegin_ added', '_onegin_ clicks', '_onegin_ pronounced', '_original_ action', '_patlabor movie_', '_patlabor_ foremost', '_pecker_ couple', '_people_ tale', '_pick_chucky_up_ demonic', '_polish_wedding_ affair', '_polish_wedding_ child', '_polish_wedding_ plot', '_polish_wedding_ pzoniaks', '_pollock_ actor', '_pollock_ alienate', '_pollock_ embodies', '_pollock_ encapsulates', '_pollock_ experience', '_pollock_ purposeful', '_poltergeist_ ends', '_porky s_', '_practical magic_', '_quite_ good', '_real_ challenge', '_real_ physical', '_real_ purpose', '_real_ source', '_reality bites_', '_really_ bad', '_really_ big', '_really_ happening', '_really_ like', '_really_ loathe', '_really_ serve', '_red harvest_', '_remains hotel_', '_require_ make', '_roxbury_ forgivable', '_roxbury_ lack', '_roxbury_ play', '_rushmore_ murray', '_rushmore_ novel', '_rushmore_ potential', '_rushmore_ president', '_rushmore_ released', '_rushmore_ tonal', '_saturday_night_live_ roxbury', '_saturday_night_live_ skit', '_saturday_night_live_ talked', '_saved_by_the_bell_ alumnus', '_saving private', '_schindler list', '_scream 2_', '_scream_ _scream', '_scream_ efforts', '_scream_ extended', '_scream_ jamie', '_scream_ tried', '_scream_ yielded', '_scream_2_ noted', '_seven_nights_ cited', '_seven_nights_ lovable', '_shaft s_big_score', '_shaft_ great', '_shaft_ just', '_shaft_ keeps', '_shaft_ little', '_shaft_ movie', '_shaft_ plot', '_shaft_ remains', '_shaft_ remake', '_shaft_in_africa_ richard', '_shine_ _basquiat_', '_should_ played', '_six_days _seven_nights_', '_snl_ producer', '_so much_', '_soldier_ brain', '_soldier_ hands', '_soldier_ proof', '_soldier_ turned', '_some_ scenes']\n"
     ]
    }
   ],
   "source": [
    "print(bigram_vectorizer.get_feature_names()[3000:3200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigram_vec = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", ngram_range=(1,1))\n",
    "tfidf_bigram_vec = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigrams = tfidf_unigram_vec.fit_transform(corpus)\n",
    "tfidf_bigrams = tfidf_bigram_vec.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['balk', 'balki', 'ball', 'ballad', 'ballads', 'ballard', 'ballentine', 'ballerina', 'ballet', 'balletic', 'ballhaus', 'ballinagra', 'balliol', 'ballisitic', 'ballistic', 'ballistics', 'balloon', 'ballooning', 'balloons', 'ballot', 'ballroom', 'balls', 'ballstein', 'ballyhoo', 'ballyhooed', 'balm', 'balmy', 'balrogs', 'balsan', 'balthazar', 'baltimore', 'balto', 'baltus', 'baluyev', 'bambi', 'bamboo', 'bamboozled', 'banal', 'banalities', 'banality', 'banana', 'bananas', 'bancroft', 'band', 'bandaged', 'bandages', 'bandanna', 'bandaras', 'banderas', 'banderes', 'bandied', 'bandies', 'bandit', 'banditos', 'bandits', 'bandmate', 'bands', 'bandstand', 'bandwagon', 'bane', 'bang', 'banged', 'bangers', 'bangkok', 'bangs', 'bangy', 'banish', 'banished', 'banishes', 'banishment', 'banisters', 'banji', 'banjo', 'banjos', 'bank', 'bankability', 'bankable', 'banker', 'bankers', 'banking', 'bankole', 'bankroll', 'bankrupt', 'bankruptcy', 'banks', 'banned', 'bannen', 'banner', 'banners', 'bannister', 'bannon', 'banquet', 'banquets', 'banshee', 'banter', 'bantering', 'bantu', 'banyon', 'banzai', 'baotian', 'baptism', 'baptist', 'baptiste', 'baptizes', 'bar', 'barage', 'baranski', 'barb', 'barbara', 'barbarians', 'barbaric', 'barbarino', 'barbarity', 'barbatus', 'barbecue', 'barbed', 'barbell', 'barbeque', 'barber', 'barbet', 'barbie', 'barbieri', 'barbs', 'barby', 'barcalow', 'barcelona', 'barclay', 'barcode', 'bard', 'bardem', 'bardsley', 'bare', 'bared', 'bareikis', 'barely', 'barenboim', 'barest', 'barf', 'barfing', 'bargain', 'bargained', 'bargaining', 'bargains', 'barge', 'barges', 'baring', 'bark', 'barked', 'barkeep', 'barkeeps', 'barker', 'barkin', 'barking', 'barks', 'barksdale', 'barletta', 'barlow', 'barmaid', 'barn', 'barnacles', 'barnes', 'barnett', 'barney', 'barnfield', 'barns', 'barntill', 'barnyard', 'baron', 'barondes', 'baronial', 'baroque', 'barr', 'barracades', 'barracking', 'barracks', 'barrage', 'barred', 'barrel', 'barreled', 'barrels', 'barren', 'barreness', 'barrie', 'barrier', 'barriers', 'barring', 'barrister', 'barroom', 'barry', 'barrymore', 'bars', 'barstool', 'bart', 'barta', 'bartellemeo', 'bartender', 'bartenders', 'barter', 'barth', 'bartholomew']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_unigram_vec.get_feature_names()[3000:3200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Naive Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a 2D Array to store (review,category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [(list(movie_reviews.words(fileid)), category)       \n",
    "                for category in movie_reviews.categories()            \n",
    "                for fileid in movie_reviews.fileids(category)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframe to preprocess reviews as sentences and assign numeric values to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_reviews= pd.DataFrame(document,columns=['movie_review','category'])\n",
    "df_movie_reviews['category_ind'] = df_movie_reviews.category.map({'neg':0, 'pos':1})\n",
    "df_movie_reviews.drop(columns=['category'],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_review</th>\n",
       "      <th>category_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard ' s quick movie review damn ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" quest for camelot \" is warner bros . ' first...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis : a mentally unstable man undergoing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        movie_review  category_ind\n",
       "0  plot : two teen couples go to a church party ,...             0\n",
       "1  the happy bastard ' s quick movie review damn ...             0\n",
       "2  it is movies like these that make a jaded movi...             0\n",
       "3  \" quest for camelot \" is warner bros . ' first...             0\n",
       "4  synopsis : a mentally unstable man undergoing ...             0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie_reviews[\"movie_review\"] = df_movie_reviews[\"movie_review\"].apply(lambda x: \" \".join(x))\n",
    "df_movie_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df_movie_reviews[\"movie_review\"],\n",
    "                                                 df_movie_reviews[\"category_ind\"], \n",
    "                                                 test_size=0.2, \n",
    "                                                 random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOW Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_unigram_vectorizer = CountVectorizer(analyzer='word', stop_words=\"english\", ngram_range=(1, 1))\n",
    "bow_bigram_vectorizer = CountVectorizer(analyzer='word', stop_words=\"english\", ngram_range=(2, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_unigram_vec = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", ngram_range=(1,1))\n",
    "tfidf_bigram_vec = TfidfVectorizer(analyzer=\"word\", stop_words=\"english\", ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating unigrams and bigrams using BOW Vectorizer and TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow_unigrams = bow_unigram_vectorizer.fit_transform(X_train)\n",
    "X_train_bow_bigrams = bow_bigram_vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_bow_unigrams = bow_unigram_vectorizer.transform(X_test)\n",
    "X_test_bow_bigrams = bow_bigram_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf_unigrams = tfidf_unigram_vec.fit_transform(X_train)\n",
    "X_train_tfidf_bigrams = tfidf_bigram_vec.fit_transform(X_train)\n",
    "X_test_tfidf_unigrams = tfidf_unigram_vec.transform(X_test)\n",
    "X_test_tfidf_bigrams = tfidf_bigram_vec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking best parameters using Randomized Search CV and evaluating Naiye Bayes using Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: precision, Best_params: {'fit_prior': 'False', 'alpha': 0.7}\n",
      "\n",
      "Naive Bayes Classification report: BOW Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       199\n",
      "           1       0.83      0.75      0.79       201\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.80      0.80      0.80       400\n",
      "weighted avg       0.80      0.80      0.80       400\n",
      "\n",
      "\n",
      "Score: recall, Best_params: {'fit_prior': 'False', 'alpha': 0.9}\n",
      "\n",
      "Naive Bayes Classification report: BOW Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       199\n",
      "           1       0.84      0.76      0.79       201\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.80      0.80       400\n",
      "\n",
      "\n",
      "Score: f1, Best_params: {'fit_prior': 'True', 'alpha': 1}\n",
      "\n",
      "Naive Bayes Classification report: BOW Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       199\n",
      "           1       0.84      0.76      0.80       201\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.81      0.81      0.80       400\n",
      "weighted avg       0.81      0.81      0.80       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_clf = MultinomialNB()\n",
    "param_grid = [\n",
    "              {'alpha': [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "               'fit_prior': ['True', 'False']}\n",
    "              ]\n",
    "scores = [\"precision\",\"recall\",\"f1\"]\n",
    "for score in scores:\n",
    "    search = RandomizedSearchCV(estimator = NB_clf, param_distributions=param_grid, scoring=score)\n",
    "    search.fit(X_train_bow_unigrams, y_train)\n",
    "    print(f\"Score: {score}, Best_params: {search.best_params_}\")\n",
    "    print()\n",
    "    print(\"Naive Bayes Classification report: BOW Unigrams\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search.predict(X_test_bow_unigrams)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: precision, Best_params: {'fit_prior': 'True', 'alpha': 0.6}\n",
      "\n",
      "Naive Bayes Classification report: BOW Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       199\n",
      "           1       0.80      0.75      0.77       201\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.78      0.78       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n",
      "\n",
      "Score: recall, Best_params: {'fit_prior': 'True', 'alpha': 0.0}\n",
      "\n",
      "Naive Bayes Classification report: BOW Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.72       199\n",
      "           1       0.71      0.79      0.75       201\n",
      "\n",
      "    accuracy                           0.73       400\n",
      "   macro avg       0.74      0.73      0.73       400\n",
      "weighted avg       0.73      0.73      0.73       400\n",
      "\n",
      "\n",
      "Score: f1, Best_params: {'fit_prior': 'True', 'alpha': 0.0}\n",
      "\n",
      "Naive Bayes Classification report: BOW Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.72       199\n",
      "           1       0.71      0.79      0.75       201\n",
      "\n",
      "    accuracy                           0.73       400\n",
      "   macro avg       0.74      0.73      0.73       400\n",
      "weighted avg       0.73      0.73      0.73       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    search = RandomizedSearchCV(estimator = NB_clf, param_distributions=param_grid, scoring=score)\n",
    "    search.fit(X_train_bow_bigrams, y_train)\n",
    "    print(f\"Score: {score}, Best_params: {search.best_params_}\")\n",
    "    print()\n",
    "    print(\"Naive Bayes Classification report: BOW Bigrams\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search.predict(X_test_bow_bigrams)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: precision, Best_params: {'fit_prior': 'True', 'alpha': 1}\n",
      "\n",
      "Naive Bayes Classification report: TFIDF Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       199\n",
      "           1       0.84      0.75      0.79       201\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.80      0.80       400\n",
      "\n",
      "\n",
      "Score: recall, Best_params: {'fit_prior': 'True', 'alpha': 0.3}\n",
      "\n",
      "Naive Bayes Classification report: TFIDF Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       199\n",
      "           1       0.84      0.76      0.80       201\n",
      "\n",
      "    accuracy                           0.81       400\n",
      "   macro avg       0.81      0.81      0.80       400\n",
      "weighted avg       0.81      0.81      0.80       400\n",
      "\n",
      "\n",
      "Score: f1, Best_params: {'fit_prior': 'True', 'alpha': 0.8}\n",
      "\n",
      "Naive Bayes Classification report: TFIDF Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81       199\n",
      "           1       0.84      0.75      0.79       201\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.81      0.80      0.80       400\n",
      "weighted avg       0.81      0.80      0.80       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    search = RandomizedSearchCV(estimator = NB_clf, param_distributions=param_grid, scoring=score)\n",
    "    search.fit(X_train_tfidf_unigrams, y_train)\n",
    "    print(f\"Score: {score}, Best_params: {search.best_params_}\")\n",
    "    print()\n",
    "    print(\"Naive Bayes Classification report: TFIDF Unigrams\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search.predict(X_test_tfidf_unigrams)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: precision, Best_params: {'fit_prior': 'True', 'alpha': 0.1}\n",
      "\n",
      "Naive Bayes Classification report: TFIDF Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.79       199\n",
      "           1       0.80      0.75      0.77       201\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.78      0.78       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n",
      "\n",
      "Score: recall, Best_params: {'fit_prior': 'True', 'alpha': 1}\n",
      "\n",
      "Naive Bayes Classification report: TFIDF Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78       199\n",
      "           1       0.80      0.73      0.76       201\n",
      "\n",
      "    accuracy                           0.77       400\n",
      "   macro avg       0.77      0.77      0.77       400\n",
      "weighted avg       0.77      0.77      0.77       400\n",
      "\n",
      "\n",
      "Score: f1, Best_params: {'fit_prior': 'False', 'alpha': 0.0}\n",
      "\n",
      "Naive Bayes Classification report: TFIDF Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.68      0.72       199\n",
      "           1       0.71      0.79      0.75       201\n",
      "\n",
      "    accuracy                           0.73       400\n",
      "   macro avg       0.74      0.73      0.73       400\n",
      "weighted avg       0.74      0.73      0.73       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    search = RandomizedSearchCV(estimator = NB_clf, param_distributions=param_grid, scoring=score)\n",
    "    search.fit(X_train_tfidf_bigrams, y_train)\n",
    "    print(f\"Score: {score}, Best_params: {search.best_params_}\")\n",
    "    print()\n",
    "    print(\"Naive Bayes Classification report: TFIDF Bigrams\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search.predict(X_test_tfidf_bigrams)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 : SVM with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_model = SVC(kernel='linear',random_state =42)\n",
    "param_grid = {'C': [1,0.2,5,10]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking best parameters using Randomized Search CV and evaluating SVM Classifier using Precision, Recall and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: precision, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: BOW Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       199\n",
      "           1       0.82      0.82      0.82       201\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.82      0.82      0.82       400\n",
      "weighted avg       0.82      0.82      0.82       400\n",
      "\n",
      "\n",
      "Score: recall, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: BOW Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       199\n",
      "           1       0.82      0.82      0.82       201\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.82      0.82      0.82       400\n",
      "weighted avg       0.82      0.82      0.82       400\n",
      "\n",
      "\n",
      "Score: f1, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: BOW Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       199\n",
      "           1       0.82      0.82      0.82       201\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.82      0.82      0.82       400\n",
      "weighted avg       0.82      0.82      0.82       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    search = RandomizedSearchCV(estimator = SVC_model, param_distributions=param_grid, scoring=score, n_iter=20)\n",
    "    search.fit(X_train_bow_unigrams, y_train)\n",
    "    print(f\"Score: {score}, Best_params: {search.best_params_}\")\n",
    "    print()\n",
    "    print(\"SVM Classification report: BOW Unigrams\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search.predict(X_test_bow_unigrams)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: precision, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: BOW Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.77       199\n",
      "           1       0.81      0.63      0.71       201\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.75      0.74      0.74       400\n",
      "weighted avg       0.75      0.74      0.74       400\n",
      "\n",
      "\n",
      "Score: recall, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: BOW Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.77       199\n",
      "           1       0.81      0.63      0.71       201\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.75      0.74      0.74       400\n",
      "weighted avg       0.75      0.74      0.74       400\n",
      "\n",
      "\n",
      "Score: f1, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: BOW Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.77       199\n",
      "           1       0.81      0.63      0.71       201\n",
      "\n",
      "    accuracy                           0.74       400\n",
      "   macro avg       0.75      0.74      0.74       400\n",
      "weighted avg       0.75      0.74      0.74       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    search = RandomizedSearchCV(estimator = SVC_model, param_distributions=param_grid, scoring=score, n_iter=20)\n",
    "    search.fit(X_train_bow_bigrams, y_train)\n",
    "    print(f\"Score: {score}, Best_params: {search.best_params_}\")\n",
    "    print()\n",
    "    print(\"SVM Classification report: BOW Bigrams\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search.predict(X_test_bow_bigrams)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: precision, Best_params: {'C': 5}\n",
      "\n",
      "SVM Classification report: TFIDF Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       199\n",
      "           1       0.84      0.83      0.83       201\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.84      0.83       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "\n",
      "Score: recall, Best_params: {'C': 0.2}\n",
      "\n",
      "SVM Classification report: TFIDF Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.73      0.77       199\n",
      "           1       0.76      0.84      0.80       201\n",
      "\n",
      "    accuracy                           0.79       400\n",
      "   macro avg       0.79      0.78      0.78       400\n",
      "weighted avg       0.79      0.79      0.78       400\n",
      "\n",
      "\n",
      "Score: f1, Best_params: {'C': 5}\n",
      "\n",
      "SVM Classification report: TFIDF Unigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       199\n",
      "           1       0.84      0.83      0.83       201\n",
      "\n",
      "    accuracy                           0.83       400\n",
      "   macro avg       0.84      0.84      0.83       400\n",
      "weighted avg       0.84      0.83      0.83       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    search = RandomizedSearchCV(estimator = SVC_model, param_distributions=param_grid, scoring=score, n_iter=20)\n",
    "    search.fit(X_train_tfidf_unigrams, y_train)\n",
    "    print(f\"Score: {score}, Best_params: {search.best_params_}\")\n",
    "    print()\n",
    "    print(\"SVM Classification report: TFIDF Unigrams\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search.predict(X_test_tfidf_unigrams)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: precision, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: TFIDF Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       199\n",
      "           1       0.78      0.79      0.78       201\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.78      0.78       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n",
      "\n",
      "Score: recall, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: TFIDF Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       199\n",
      "           1       0.78      0.79      0.78       201\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.78      0.78       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n",
      "\n",
      "Score: f1, Best_params: {'C': 1}\n",
      "\n",
      "SVM Classification report: TFIDF Bigrams\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.77      0.78       199\n",
      "           1       0.78      0.79      0.78       201\n",
      "\n",
      "    accuracy                           0.78       400\n",
      "   macro avg       0.78      0.78      0.78       400\n",
      "weighted avg       0.78      0.78      0.78       400\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    search = RandomizedSearchCV(estimator = SVC_model, param_distributions=param_grid, scoring=score, n_iter=20)\n",
    "    search.fit(X_train_tfidf_bigrams, y_train)\n",
    "    print(f\"Score: {score}, Best_params: {search.best_params_}\")\n",
    "    print()\n",
    "    print(\"SVM Classification report: TFIDF Bigrams\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, search.predict(X_test_tfidf_bigrams)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "* For Naive-Bayes, Unigrams and Precision Metric give the best results with Precision score of 0.81. Rest fall in the range of (0.71-0.79)\n",
    "* For SVM, TFIDF Unigrams with C=5 proves to be best model, as precision and f1 give score of 0.84."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "TextClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
